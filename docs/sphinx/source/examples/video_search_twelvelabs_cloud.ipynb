{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "BXfYSnoaYyl4",
   "metadata": {
    "id": "BXfYSnoaYyl4"
   },
   "source": [
    "<picture>\n",
    "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
    "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
    "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
    "</picture>\n",
    "\n",
    "\n",
    "# Video Search and Retrieval with Vespa and TwelveLabs\n",
    "\n",
    "In the following notebook, we will demonstrate how to leverage [TwelveLabs](https://www.twelvelabs.io/) `Marengo-retrieval-2.7` a SOTA multimodal embedding model to demonstrate a use case of video embeddings storage and semantic search retrieval using Vespa.ai.\n",
    "\n",
    "The steps we will take in this notebook are:\n",
    "\n",
    "1. Setup and configuration\n",
    "2. Generate Attributes and Embeddings for 3 sample videos using the TwelveLabs python SDK.\n",
    "3. Deploy the Vespa application to Vespa Cloud and Feed the Data\n",
    "4. Perform a semantic search with hybrid multi-phase ranking on the videos\n",
    "5. Review the results\n",
    "6. Cleanup\n",
    "\n",
    "All the steps that are needed to provision the Vespa application, including feeding the data, can be done by running this notebook.\n",
    "We have tried to make it easy for others to run this notebook, to create your own Video semantic search application using TwelveLabs models with Vespa.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/video_search_twelvelabs_cloud.ipynb)\n",
    "\n",
    "## 1. Setup and Configuration\n",
    "\n",
    "For reference, this is the Python version used for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "C2muzvA8yyXFRL7zrDpEgpmJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2muzvA8yyXFRL7zrDpEgpmJ",
    "outputId": "baabbc0a-4a93-4795-e36a-152030b6e287",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NPWxNjsXa5vd",
   "metadata": {
    "id": "NPWxNjsXa5vd"
   },
   "source": [
    "### 1.1 Install libraries\n",
    "\n",
    "Install the required Python dependencies from TwelveLabs python SDK and pyvespa python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "OzBunhAMSMUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzBunhAMSMUF",
    "outputId": "ee27446c-d85d-4aea-b8c0-b570fe7bf025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvespa in /usr/local/lib/python3.11/dist-packages (0.53.0)\n",
      "Requirement already satisfied: vespacli in /usr/local/lib/python3.11/dist-packages (8.478.26)\n",
      "Requirement already satisfied: twelvelabs in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pyvespa) (2.32.3)\n",
      "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from pyvespa) (1.0.0)\n",
      "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from pyvespa) (7.1.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyvespa) (3.1.5)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from pyvespa) (43.0.3)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from pyvespa) (3.11.12)\n",
      "Requirement already satisfied: httpx[http2] in /usr/local/lib/python3.11/dist-packages (from pyvespa) (0.28.1)\n",
      "Requirement already satisfied: tenacity>=8.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvespa) (9.0.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pyvespa) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from pyvespa) (2.8.2)\n",
      "Requirement already satisfied: fastcore>=1.7.8 in /usr/local/lib/python3.11/dist-packages (from pyvespa) (1.7.29)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from pyvespa) (5.3.1)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from twelvelabs) (2.10.6)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastcore>=1.7.8->pyvespa) (24.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx[http2]->pyvespa) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->twelvelabs) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->twelvelabs) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->pyvespa) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (1.18.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->pyvespa) (1.17.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyvespa) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pyvespa) (3.4.1)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyvespa) (3.0.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->pyvespa) (2.22)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]->pyvespa) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]->pyvespa) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx[http2]->pyvespa) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyvespa vespacli twelvelabs pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8veAJGipbjVA",
   "metadata": {
    "id": "8veAJGipbjVA"
   },
   "source": [
    "Import all the required packages in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Ojdxaw85h9tV",
   "metadata": {
    "id": "Ojdxaw85h9tV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "from vespa.package import (\n",
    "    ApplicationPackage,\n",
    "    Field,\n",
    "    Schema,\n",
    "    Document,\n",
    "    HNSW,\n",
    "    RankProfile,\n",
    "    FieldSet,\n",
    "    SecondPhaseRanking,\n",
    "    Function,\n",
    ")\n",
    "\n",
    "from vespa.deployment import VespaCloud\n",
    "from vespa.io import VespaResponse, VespaQueryResponse\n",
    "\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.models.embed import EmbeddingsTask\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ukp_0PzHXAf-",
   "metadata": {
    "id": "Ukp_0PzHXAf-"
   },
   "source": [
    "### 1.2 Get a TwelveLabs API key\n",
    "[Sign-up](https://auth.twelvelabs.io/u/signup) for TwelveLabs.\n",
    "\n",
    "After logging in, navigate to your profile and get your [API key](https://playground.twelvelabs.io/dashboard/api-key). Copy it and paste it below.\n",
    "\n",
    "The Free plan includes indexing of 600 mins of videos, which should be sufficient to explore the capabilities of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e381016",
   "metadata": {
    "id": "7e381016"
   },
   "outputs": [],
   "source": [
    "TL_API_KEY = os.getenv(\"TL_API_KEY\") or input(\"Enter your TL_API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AfCgIhMPXnQQ",
   "metadata": {
    "id": "AfCgIhMPXnQQ"
   },
   "source": [
    "### 1.3 Sign-up for a Vespa Trial Account\n",
    "\n",
    "**Pre-requisite**:\n",
    "- Spin-up a Vespa Cloud [Trial](https://vespa.ai/free-trial) account.\n",
    "- Login to the account you just created and create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/).\n",
    "- Save the tenant name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B7uKLKsrYQgT",
   "metadata": {
    "id": "B7uKLKsrYQgT"
   },
   "source": [
    "### 1.4 Setup the tenant name and the application name\n",
    "\n",
    "- Paste below the name of the tenant name.\n",
    "- Give your application a name. Note that the name cannot have `-` or `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zJlBCg6ahzJM",
   "metadata": {
    "id": "zJlBCg6ahzJM"
   },
   "outputs": [],
   "source": [
    "# Replace with your tenant name from the Vespa Cloud Console\n",
    "tenant_name = \"vespa-team\"\n",
    "# Replace with your application name (does not need to exist yet)\n",
    "application = \"videosearch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ga0DUN47dLjK",
   "metadata": {
    "id": "Ga0DUN47dLjK"
   },
   "source": [
    "## 2. Generate Attributes and Embeddings for sample videos using TwelveLabs Embedding API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jXol6MHVy1i",
   "metadata": {
    "id": "7jXol6MHVy1i"
   },
   "source": [
    "### 2.1 Generate attributes on the videos\n",
    "\n",
    "In this section, we will leverage the [Pegasus 1.2](https://docs.twelvelabs.io/v1.3/docs/concepts/models/pegasus) generative model to generate some attributes about our videos to store as part of the searchable information in Vespa. Attributes we want to store as part of the videos include:\n",
    "\n",
    "- Keywords\n",
    "- Summaries\n",
    "\n",
    "For video samples, we are selecting the 3 videos in the array below from the [Internet Archive](https://archive.org/).\n",
    "\n",
    "You can customize this code with the urls of your choice. Note that there are certain restrictions such as the resolution of the videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eQkLI-moZPhL",
   "metadata": {
    "id": "eQkLI-moZPhL"
   },
   "outputs": [],
   "source": [
    "VIDEO_URLs = [\n",
    "    \"https://archive.org/download/the-end-blue-sky-studios/The%20End%281080P_60FPS%29.ia.mp4\",\n",
    "    \"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\",\n",
    "    \"https://archive.org/download/The_Worm_in_the_Apple_Animation_Test/AnimationTest.mov\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yZa-YDeNZ63r",
   "metadata": {
    "id": "yZa-YDeNZ63r"
   },
   "source": [
    "In order to generate text on the videos, the prerequisite is to upload the videos and index them. Let's first create an index below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "elAj0cm1Upaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elAj0cm1Upaa",
    "outputId": "42441224-3947-4d32-cf2a-2c33b0d0da4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Index:Vespa_1739986655\n",
      "Created index: id=67b616dfc82670193cb59a05 name=Vespa_1739986655 models=root=[Model(name='pegasus1.2', options=['visual', 'audio'], addons=None, finetuned=False)]\n"
     ]
    }
   ],
   "source": [
    "# Spin-up session\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "# Generating Index Name\n",
    "timestamp = int(datetime.now().timestamp())\n",
    "index_name = \"Vespa_\" + str(timestamp)\n",
    "\n",
    "# Create Index\n",
    "print(\"Creating Index:\" + index_name)\n",
    "index = client.index.create(\n",
    "    name=index_name,\n",
    "    models=[\n",
    "        {\n",
    "            \"name\": \"pegasus1.2\",\n",
    "            \"options\": [\"visual\", \"audio\"],\n",
    "        }\n",
    "    ],\n",
    "    addons=[\"thumbnail\"],  # Optional\n",
    ")\n",
    "print(f\"Created index: id={index.id} name={index.name} models={index.models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ylbZo766ayig",
   "metadata": {
    "id": "ylbZo766ayig"
   },
   "source": [
    "We can now upload the videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "oEKeONmX7ffB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEKeONmX7ffB",
    "outputId": "23cd7603-5bbf-4ca3-eb3d-6f901e1ba767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task created successfully! Task ID: 67b616e4c82670193cb59a06\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=ready\n",
      "Indexing done: Task(id='67b616e4c82670193cb59a06', created_at='2025-02-19T17:37:40.286Z', updated_at='2025-02-19T17:37:40.286Z', index_id='67b616dfc82670193cb59a05', video_id='67b616e551e07a2910a9b956', status='ready', system_metadata={'filename': 'HnVideoEditor_2022_10_29_205557707.ia', 'duration': 221.9666671, 'width': 854, 'height': 480}, hls=None)\n",
      "Uploaded https://ia801503.us.archive.org/27/items/hide-and-seek-with-giant-jenny/HnVideoEditor_2022_10_29_205557707.ia.mp4. The unique identifer of your video is 67b616e551e07a2910a9b956.\n",
      "Task created successfully! Task ID: 67b6179dc82670193cb59a0a\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=ready\n",
      "Indexing done: Task(id='67b6179dc82670193cb59a0a', created_at='2025-02-19T17:40:45.027Z', updated_at='2025-02-19T17:40:45.027Z', index_id='67b616dfc82670193cb59a05', video_id='67b617b6589f15770cd94602', status='ready', system_metadata={'filename': 'twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net', 'duration': 1448.8000001, 'width': 640, 'height': 480}, hls=None)\n",
      "Uploaded https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4. The unique identifer of your video is 67b617b6589f15770cd94602.\n",
      "Task created successfully! Task ID: 67b618c0c82670193cb59a10\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=ready\n",
      "Indexing done: Task(id='67b618c0c82670193cb59a10', created_at='2025-02-19T17:45:36.117Z', updated_at='2025-02-19T17:45:36.117Z', index_id='67b616dfc82670193cb59a05', video_id='67b618c2589f15770cd94603', status='ready', system_metadata={'filename': 'S2E12.ia', 'duration': 659.9200001, 'width': 854, 'height': 480}, hls=None)\n",
      "Uploaded https://dn720401.ca.archive.org/0/items/mr-bean-the-animated-series-holiday-for-teddy/S2E12.ia.mp4. The unique identifer of your video is 67b618c2589f15770cd94603.\n"
     ]
    }
   ],
   "source": [
    "# Capturing index id for upload\n",
    "index_id = index.id\n",
    "\n",
    "\n",
    "def on_task_update(task: EmbeddingsTask):\n",
    "    print(f\"  Status={task.status}\")\n",
    "\n",
    "\n",
    "for video_url in VIDEO_URLs:\n",
    "    # Create a video indexing task\n",
    "    task = client.task.create(index_id=index_id, url=video_url)\n",
    "    print(f\"Task created successfully! Task ID: {task.id}\")\n",
    "    status = task.wait_for_done(sleep_interval=10, callback=on_task_update)\n",
    "    print(f\"Indexing done: {status}\")\n",
    "    if task.status != \"ready\":\n",
    "        raise RuntimeError(f\"Indexing failed with status {task.status}\")\n",
    "    print(\n",
    "        f\"Uploaded {video_url}. The unique identifer of your video is {task.video_id}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yakP4RZabFxR",
   "metadata": {
    "id": "yakP4RZabFxR"
   },
   "source": [
    "Now that the videos have been uploaded, we can generate the keywords, and summaries on the videos below. You will notice on the output that the video uploaded last is the one that is processed first in this stage. This matters since we store other attributes on the videos on arrays (eg URLs, Titles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z0m24cYj9-FC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0m24cYj9-FC",
    "outputId": "c5115b41-f406-4131-cca6-733715c71ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text for 67b618c2589f15770cd94603\n",
      "Summary: The video showcases a series of comedic scenes featuring Mr. Bean, who embarks on a holiday at Seaview Hotel. Throughout his stay, he engages in various mishaps, including accidentally starting a car and exchanging toys with a little girl. At the beach, he interacts with a family and participates in a dodgem car game, where he manages to take possession of a teddy bear, causing confusion and amusement. The video concludes with Mr. Bean back at his room, reflecting on his holiday adventures through photographs, highlighting his characteristic blend of humor and awkwardness.\n",
      "Open-ended Text: MrBean, TeddyBear, Beach, BumperCars, Holiday\n",
      "Generating text for 67b617b6589f15770cd94602\n",
      "Summary: The video is an animated adaptation of \"A Visit from St. Nicholas,\" commonly known as \"The Night Before Christmas,\" narrated and sung by Joel Grey. It features a town where the residents, including a clockmaker named Joshua Trundle and his family, are troubled by Santa's absence due to a critical letter published in the local newspaper. The story unfolds with the clockmaker's son, Albert, realizing his mistake and attempting to fix a malfunctioning clock in the town hall that was meant to welcome Santa. Despite initial setbacks, the community's efforts eventually lead to Santa's arrival, restoring joy and belief in the magic of Christmas. The video concludes with Santa Claus descending through chimneys to deliver gifts, symbolizing the triumph of hope and the spirit of the holiday.\n",
      "Open-ended Text: Christmas Eve, Santa Claus, Clockmaker, Snowy Night, Mouse Characters\n",
      "Generating text for 67b616e551e07a2910a9b956\n",
      "Summary: The video showcases a series of animated scenes featuring a panda and three cartoon wolves engaging in various activities, from watching TV to building a miniature cardboard town. The wolves, along with a pink dog and a green alien, encounter unexpected situations such as a giant fox descending upon them and a chase involving toy cars and a convertible. The narrative culminates in a heartwarming reunion under a bridge, where the characters express gratitude for their day's adventures. Throughout the video, the characters display a range of emotions and interactions, highlighting themes of friendship and teamwork.\n",
      "Open-ended Text: Cartoon, Wolves, Hide-and-Seek, Cardboard City, Alien\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "summaries = []\n",
    "keywords_array = []\n",
    "\n",
    "# Get all videos in an Index\n",
    "videos = client.index.video.list(index_id)\n",
    "for video in videos:\n",
    "    print(f\"Generating text for {video.id}\")\n",
    "\n",
    "    res = client.summarize(\n",
    "        video_id=video.id,\n",
    "        type=\"summary\",\n",
    "        prompt=\"Generate an abstract of the video serving as metadata on the video, up to five sentences.\",\n",
    "    )\n",
    "    \n",
    "    wrapped = textwrap.wrap(res.summary, width=120)\n",
    "    print(\"Summary:\")\n",
    "    print(\"\\n\".join(wrapped))\n",
    "    summaries.append(res.summary)\n",
    "\n",
    "    keywords = client.analyze(\n",
    "        video_id=video.id,\n",
    "        prompt=\"Based on this video, I want to generate five keywords for SEO (Search Engine Optimization). Provide just the keywords as a comma delimited list without any additional text.\",\n",
    "    )\n",
    "    print(f\"Open-ended Text: {keywords.data}\")\n",
    "    keywords_array.append(keywords.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VBebeBFcc7vx",
   "metadata": {
    "id": "VBebeBFcc7vx"
   },
   "source": [
    "We need to store the titles of the videos as an additional attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sPliZOSZU3em",
   "metadata": {
    "id": "sPliZOSZU3em"
   },
   "outputs": [],
   "source": [
    "# Creating array with titles\n",
    "titles = [\n",
    "    \"Mr. Bean the Animated Series Holiday for Teddy\",\n",
    "    \"Twas the night before Christmas\",\n",
    "    \"Hide and Seek with Giant Jenny\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aJ2Rr5fDD8",
   "metadata": {
    "id": "c4aJ2Rr5fDD8"
   },
   "source": [
    "## 2.2 Generate Embeddings\n",
    "\n",
    "The following code leverages the [Embed API](https://docs.twelvelabs.io/docs/create-video-embeddings) to create an asynchronous embedding task to embed the sample videos.\n",
    "\n",
    "Twelve Labs video embeddings capture all the subtle cues and interactions between different modalities, including the visual expressions, body language, spoken words, and the overall context of the video, encapsulating the essence of all these modalities and their interrelations over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "qm2DXkatR1pP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qm2DXkatR1pP",
    "outputId": "f386fc9d-c41f-4626-ca0c-4f283a147aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created task: id=67b61b3567ce2ae76ec6b3eb model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n",
      "Created task: id=67b61b7e67ce2ae76ec6b3f4 model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n",
      "Created task: id=67b61c0c67ce2ae76ec6b3fa model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n"
     ]
    }
   ],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "# Initialize an array to store the task IDs as strings\n",
    "task_ids = []\n",
    "\n",
    "for url in VIDEO_URLs:\n",
    "    task = client.embed.task.create(model_name=\"Marengo-retrieval-2.7\", video_url=url)\n",
    "    print(\n",
    "        f\"Created task: id={task.id} model_name={task.model_name} status={task.status}\"\n",
    "    )\n",
    "    # Append the task ID to the array\n",
    "    task_ids.append(str(task.id))\n",
    "    status = task.wait_for_done(sleep_interval=10, callback=on_task_update)\n",
    "    print(f\"Embedding done: {status}\")\n",
    "    if task.status != \"ready\":\n",
    "        raise RuntimeError(f\"Embedding failed with status {task.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6R198-KVq9if",
   "metadata": {
    "id": "6R198-KVq9if"
   },
   "source": [
    "## 2.3 Retrieve Embeddings\n",
    "\n",
    "Once the embedding task is completed, we can retrieve the results of the embedding task based on the task_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9By4UdCgGChw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9By4UdCgGChw",
    "outputId": "2b1be60e-447a-4dc7-b0ea-28608c3808d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: 67b61b3567ce2ae76ec6b3eb\n",
      "Status: ready\n",
      "Task ID: 67b61b7e67ce2ae76ec6b3f4\n",
      "Status: ready\n",
      "Task ID: 67b61c0c67ce2ae76ec6b3fa\n",
      "Status: ready\n"
     ]
    }
   ],
   "source": [
    "# Spin-up session\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "# Initialize an array to store the task objects directly\n",
    "tasks = []\n",
    "\n",
    "for task_id in task_ids:\n",
    "    # Retrieve the task\n",
    "    task = client.embed.task.retrieve(task_id)\n",
    "    tasks.append(task)\n",
    "\n",
    "    # Print task details\n",
    "    print(f\"Task ID: {task.id}\")\n",
    "    print(f\"Status: {task.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpuVxCshxoD3",
   "metadata": {
    "id": "kpuVxCshxoD3"
   },
   "source": [
    "We can now review the output structure of the first segment for each one of these videos. This output will help us define the schema to store the embeddings in Vespa in the second part of this notebook.\n",
    "\n",
    "From looking at this output, the video has been embedded into chunks of 6 seconds each (default configurable value in the Embed API). Each embedding has a float vector of dimension 1024.\n",
    "\n",
    "The number of segments generated vary per video, based on the length of the videos ranging from 37 to 242 segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4iyjmzpYsRUz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iyjmzpYsRUz",
    "outputId": "242c5746-f198-42ec-f973-39933a9ce5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67b61b3567ce2ae76ec6b3eb\n",
      "start_offset_sec: float : 0.0\n",
      "end_offset_sec: float : 6.0\n",
      "embedding_scope: str : clip\n",
      "embeddings_float: list of size 1024 (truncated to 5 items): [0.030361895, 0.008698823, -0.0048321243, -0.019013105, -0.011488311] \n",
      "Total Number of segments: 37\n",
      "67b61b7e67ce2ae76ec6b3f4\n",
      "start_offset_sec: float : 0.0\n",
      "end_offset_sec: float : 6.0\n",
      "embedding_scope: str : clip\n",
      "embeddings_float: list of size 1024 (truncated to 5 items): [0.024328815, -0.0035867887, 0.016065866, 0.02501548, 0.007778642] \n",
      "Total Number of segments: 242\n",
      "67b61c0c67ce2ae76ec6b3fa\n",
      "start_offset_sec: float : 0.0\n",
      "end_offset_sec: float : 6.0\n",
      "embedding_scope: str : clip\n",
      "embeddings_float: list of size 1024 (truncated to 5 items): [0.04080625, 0.0086980555, 0.00096186635, -0.00607, -0.020250283] \n",
      "Total Number of segments: 110\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task.id)\n",
    "    # Display data types of each field\n",
    "    for key, value in task.video_embedding.segments[0]:\n",
    "        if isinstance(value, list):\n",
    "            print(\n",
    "                f\"{key}: list of size {len(value)} (truncated to 5 items): {value[:5]} \"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{key}: {type(value).__name__} : {value}\")\n",
    "    print(f\"Total Number of segments: {len(task.video_embedding.segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1iscs7g-5xOD",
   "metadata": {
    "id": "1iscs7g-5xOD"
   },
   "source": [
    "# 3. Deploy a Vespa Application\n",
    "\n",
    "At this point, we are ready to deploy a Vespa Application. We have generated the attributes we needed on each video, as well as the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hbZ-pJO37-1O",
   "metadata": {
    "id": "hbZ-pJO37-1O"
   },
   "source": [
    "## 3.1 Create an Application Package\n",
    "\n",
    "The [application package](https://vespa-engine.github.io/pyvespa/api/vespa/package.html)\n",
    "has all the Vespa configuration files -\n",
    "create one from scratch:\n",
    "\n",
    "The Vespa schema deployed as part of the package is called `videos`. All the fields are matching the output of the Twelvelabs Embed API above. Refer to the [Vespa documentation](https://docs.vespa.ai/en/reference/schema-reference.html) for more information on the schema specification.\n",
    "\n",
    "We can first define the schema using pyvespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "T941tSJOiDCx",
   "metadata": {
    "id": "T941tSJOiDCx"
   },
   "outputs": [],
   "source": [
    "videos_schema = Schema(\n",
    "    name=\"videos\",\n",
    "    document=Document(\n",
    "        fields=[\n",
    "            Field(name=\"video_url\", type=\"string\", indexing=[\"summary\"]),\n",
    "            Field(\n",
    "                name=\"title\",\n",
    "                type=\"string\",\n",
    "                indexing=[\"index\", \"summary\"],\n",
    "                match=[\"text\"],\n",
    "                index=\"enable-bm25\",\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"keywords\",\n",
    "                type=\"string\",\n",
    "                indexing=[\"index\", \"summary\"],\n",
    "                match=[\"text\"],\n",
    "                index=\"enable-bm25\",\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"video_summary\",\n",
    "                type=\"string\",\n",
    "                indexing=[\"index\", \"summary\"],\n",
    "                match=[\"text\"],\n",
    "                index=\"enable-bm25\",\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"embedding_scope\", type=\"string\", indexing=[\"attribute\", \"summary\"]\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"start_offset_sec\",\n",
    "                type=\"array<float>\",\n",
    "                indexing=[\"attribute\", \"summary\"],\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"end_offset_sec\",\n",
    "                type=\"array<float>\",\n",
    "                indexing=[\"attribute\", \"summary\"],\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"embeddings\",\n",
    "                type=\"tensor<float>(p{},x[1024])\",\n",
    "                indexing=[\"index\", \"attribute\"],\n",
    "                ann=HNSW(distance_metric=\"angular\"),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "fieldsets = (\n",
    "    [\n",
    "        FieldSet(\n",
    "            name=\"default\",\n",
    "            fields=[\"title\", \"keywords\", \"video_summary\"],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "mapfunctions = [\n",
    "    Function(\n",
    "        name=\"similarities\",\n",
    "        expression=\"\"\"\n",
    "                      sum(\n",
    "                          query(q) * attribute(embeddings), x\n",
    "                          )\n",
    "                      \"\"\",\n",
    "    ),\n",
    "    Function(\n",
    "        name=\"bm25_score\",\n",
    "        expression=\"bm25(title) + bm25(keywords) + bm25(video_summary)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "semantic_rankprofile = RankProfile(\n",
    "    name=\"hybrid\",\n",
    "    inputs=[(\"query(q)\", \"tensor<float>(x[1024])\")],\n",
    "    first_phase=\"bm25_score\",\n",
    "    second_phase=SecondPhaseRanking(\n",
    "        expression=\"closeness(field, embeddings)\", rerank_count=10\n",
    "    ),\n",
    "    match_features=[\"closest(embeddings)\"],\n",
    "    summary_features=[\"similarities\"],\n",
    "    functions=mapfunctions,\n",
    ")\n",
    "\n",
    "videos_schema.add_rank_profile(semantic_rankprofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HsUrAY78k6Xr",
   "metadata": {
    "id": "HsUrAY78k6Xr"
   },
   "source": [
    "We can now create the package based on the previous schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "qvRl19JFBJGS",
   "metadata": {
    "id": "qvRl19JFBJGS"
   },
   "outputs": [],
   "source": [
    "# Create the Vespa application package\n",
    "package = ApplicationPackage(name=application, schema=[videos_schema])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_BJzOAOM_QFW",
   "metadata": {
    "id": "_BJzOAOM_QFW"
   },
   "source": [
    "## 3.2 Deploy the Application Package\n",
    "\n",
    "The app is now defined and ready to deploy to Vespa Cloud.\n",
    "\n",
    "Deploy `package` to Vespa Cloud, by creating an instance of\n",
    "[VespaCloud](https://vespa-engine.github.io/pyvespa/api/vespa/deployment#VespaCloud):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "or8HJb5Q26h5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or8HJb5Q26h5",
    "outputId": "8c98f519-8185-4251-b93b-5814403b4143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting application...\n",
      "Running: vespa config set application vespa-presales.videosearch\n",
      "Setting target cloud...\n",
      "Running: vespa config set target cloud\n",
      "\n",
      "No api-key found for control plane access. Using access token.\n",
      "No auth.json found. Please authenticate.\n",
      "Your Device Confirmation code is: QVNV-TRSK\n",
      "Automatically open confirmation page in your default browser? [Y/n] Y\n",
      "Y\n",
      "Opened link in your browser: https://login.console.vespa-cloud.com/activate?user_code=QVNV-TRSK\n",
      "/usr/bin/xdg-open: 882: www-browser: not found\n",
      "/usr/bin/xdg-open: 882: links2: not found\n",
      "/usr/bin/xdg-open: 882: elinks: not found\n",
      "/usr/bin/xdg-open: 882: links: not found\n",
      "/usr/bin/xdg-open: 882: lynx: not found\n",
      "/usr/bin/xdg-open: 882: w3m: not found\n",
      "xdg-open: no method available for opening 'https://login.console.vespa-cloud.com/activate?user_code=QVNV-TRSK'\n",
      "Couldn't open the URL, please do it manually\n",
      "Waiting for login to complete in browser ... done\n",
      "\u001b[33mWarning:\u001b[0m Could not store the refresh token locally. You may need to login again once your access token expires\n",
      "\u001b[32mSuccess:\u001b[0m Logged in\n",
      " auth.json created at /root/.vespa/auth.json\n",
      "Successfully obtained access token for control plane access.\n",
      "Certificate and key not found in /content/.vespa or /root/.vespa/vespa-presales.videosearch.default: Creating new cert/key pair with vespa CLI.\n",
      "Generating certificate and key...\n",
      "Running: vespa auth cert -N\n",
      "Success: Certificate written to '/root/.vespa/vespa-presales.videosearch.default/data-plane-public-cert.pem'\n",
      "Success: Private key written to '/root/.vespa/vespa-presales.videosearch.default/data-plane-private-key.pem'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vespa_cloud = VespaCloud(\n",
    "    tenant=tenant_name,\n",
    "    application=application,\n",
    "    application_package=package,\n",
    "    key_content=os.getenv(\"VESPA_TEAM_API_KEY\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nLeaLna86ApZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLeaLna86ApZ",
    "outputId": "9eb4c057-f13a-4164-f2ed-eecc968c6f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment started in run 1 of dev-aws-us-east-1c for vespa-presales.videosearch. This may take a few minutes the first time.\n",
      "INFO    [18:05:07]  Deploying platform version 8.482.31 and application dev build 1 for dev-aws-us-east-1c of default ...\n",
      "INFO    [18:05:08]  Using CA signed certificate version 1\n",
      "INFO    [18:05:08]  Using 1 nodes in container cluster 'videosearch_container'\n",
      "INFO    [18:05:11]  Session 2384 for tenant 'vespa-presales' prepared and activated.\n",
      "INFO    [18:05:33]  ######## Details for all nodes ########\n",
      "INFO    [18:05:42]  h113694g.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [18:05:42]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "INFO    [18:05:42]  --- container-clustercontroller on port 19050 has not started \n",
      "INFO    [18:05:42]  --- metricsproxy-container on port 19092 has not started \n",
      "INFO    [18:05:42]  h113694b.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [18:05:42]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "INFO    [18:05:42]  --- logserver-container on port 4080 has not started \n",
      "INFO    [18:05:42]  --- metricsproxy-container on port 19092 has not started \n",
      "INFO    [18:05:42]  h113669a.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [18:05:42]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "INFO    [18:05:42]  --- storagenode on port 19102 has not started \n",
      "INFO    [18:05:42]  --- searchnode on port 19107 has not started \n",
      "INFO    [18:05:42]  --- distributor on port 19111 has not started \n",
      "INFO    [18:05:42]  --- metricsproxy-container on port 19092 has not started \n",
      "INFO    [18:05:42]  h113963a.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [18:05:42]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "INFO    [18:05:42]  --- container on port 4080 has not started \n",
      "INFO    [18:05:42]  --- metricsproxy-container on port 19092 has not started \n",
      "INFO    [18:07:10]  Waiting for convergence of 10 services across 4 nodes\n",
      "INFO    [18:07:10]  3 nodes booting\n",
      "INFO    [18:07:10]  10 application services still deploying\n",
      "DEBUG   [18:07:17]  h113694b.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "DEBUG   [18:07:17]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "DEBUG   [18:07:17]  --- logserver-container on port 4080 has not started \n",
      "DEBUG   [18:07:17]  --- metricsproxy-container on port 19092 has not started \n",
      "DEBUG   [18:07:17]  h113669a.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "DEBUG   [18:07:17]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "DEBUG   [18:07:17]  --- storagenode on port 19102 has not started \n",
      "DEBUG   [18:07:17]  --- searchnode on port 19107 has not started \n",
      "DEBUG   [18:07:17]  --- distributor on port 19111 has not started \n",
      "DEBUG   [18:07:17]  --- metricsproxy-container on port 19092 has not started \n",
      "DEBUG   [18:07:17]  h113963a.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "DEBUG   [18:07:17]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "DEBUG   [18:07:17]  --- container on port 4080 has not started \n",
      "DEBUG   [18:07:17]  --- metricsproxy-container on port 19092 has not started \n",
      "DEBUG   [18:07:17]  h113694g.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "DEBUG   [18:07:17]  --- platform vespa/cloud-tenant-rhel8:8.482.31\n",
      "DEBUG   [18:07:17]  --- container-clustercontroller on port 19050 has not started \n",
      "DEBUG   [18:07:17]  --- metricsproxy-container on port 19092 has not started \n",
      "INFO    [18:08:06]  Found endpoints:\n",
      "INFO    [18:08:06]  - dev.aws-us-east-1c\n",
      "INFO    [18:08:06]   |-- https://aefbf207.f5d60452.z.vespa-app.cloud/ (cluster 'videosearch_container')\n",
      "INFO    [18:08:22]  Deployment complete!\n",
      "Only region: aws-us-east-1c available in dev environment.\n",
      "Found mtls endpoint for videosearch_container\n",
      "URL: https://aefbf207.f5d60452.z.vespa-app.cloud/\n",
      "Application is up!\n"
     ]
    }
   ],
   "source": [
    "app = vespa_cloud.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v-58uKvQ_78K",
   "metadata": {
    "id": "v-58uKvQ_78K"
   },
   "source": [
    "## 3.3 Feed the Vespa Application\n",
    "\n",
    "The `vespa_feed` feed format for `pyvespa` expects a dict with the keys `id` and `fields`:\n",
    "\n",
    "`{ \"id\": \"vespa-document-id\", \"fields\": {\"vespa_field\": \"vespa-field-value\"}}`\n",
    "\n",
    "For the id, we will use a md5 hash of the video url.\n",
    "\n",
    "The video embedding output segments are added to the `fields` in `vespa_feed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfpazeii8Abp",
   "metadata": {
    "id": "dfpazeii8Abp"
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store Vespa feed documents\n",
    "vespa_feed = []\n",
    "\n",
    "# Need to reverse VIDEO_URLS as keywords/summaries generated in reverse order\n",
    "VIDEO_URLs.reverse()\n",
    "\n",
    "# Iterate through each task and corresponding metadata\n",
    "for i, task in enumerate(tasks):\n",
    "    video_url = VIDEO_URLs[i]\n",
    "    title = titles[i]\n",
    "    keywords = keywords_array[i]\n",
    "    summary = summaries[i]\n",
    "\n",
    "    start_offsets = []  # Reset for each video\n",
    "    end_offsets = []  # Reset for each video\n",
    "    embeddings = {}  # Reset for each video\n",
    "\n",
    "    # Iterate through the video embedding segments\n",
    "    for index, segment in enumerate(task.video_embedding.segments):\n",
    "        # Append start and end offsets as floats\n",
    "        start_offsets.append(float(segment.start_offset_sec))\n",
    "        end_offsets.append(float(segment.end_offset_sec))\n",
    "\n",
    "        # Add embedding to a multi-dimensional dictionary with index as the key\n",
    "        embeddings[str(index)] = list(map(float, segment.embeddings_float))\n",
    "\n",
    "    # Create Vespa document for each task\n",
    "    for segment in task.video_embedding.segments:\n",
    "        start_offset_sec = segment.start_offset_sec\n",
    "        end_offset_sec = segment.end_offset_sec\n",
    "        embedding = list(map(float, segment.embeddings_float))\n",
    "\n",
    "        # Create a unique ID by hashing the URL and segment index\n",
    "        id_hash = hashlib.md5(f\"{video_url}_{index}\".encode()).hexdigest()\n",
    "\n",
    "        document = {\n",
    "            \"id\": id_hash,\n",
    "            \"fields\": {\n",
    "                \"video_url\": video_url,\n",
    "                \"title\": title,\n",
    "                \"keywords\": keywords,\n",
    "                \"video_summary\": summary,\n",
    "                \"embedding_scope\": segment.embedding_scope,\n",
    "                \"start_offset_sec\": start_offsets,\n",
    "                \"end_offset_sec\": end_offsets,\n",
    "                \"embeddings\": embeddings,\n",
    "            },\n",
    "        }\n",
    "    vespa_feed.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G7KUVns0BSzZ",
   "metadata": {
    "id": "G7KUVns0BSzZ"
   },
   "source": [
    "We can quickly validate the number of the number of documents created (one for each video), and visually check the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aZDNkQEXMU15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZDNkQEXMU15",
    "outputId": "2e7c2fa2-ec78-48a2-eb2a-535d205d1b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 3\n"
     ]
    }
   ],
   "source": [
    "# Print Vespa feed size and an example\n",
    "print(f\"Total documents created: {len(vespa_feed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "TF2GsukrA9Xw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TF2GsukrA9Xw",
    "outputId": "4e2b3e49-f2fa-40c5-f2db-b013dd69cac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"0b1fc68a17391fb58102a539ed290d27\",\n",
      "    \"fields\": {\n",
      "        \"video_url\": \"https://ia801503.us.archive.org/27/items/hide-and-seek-with-giant-jenny/HnVideoEditor_2022_10_29_205557707.ia.mp4\",\n",
      "        \"title\": \"Hide and Seek with Giant Jenny\",\n",
      "        \"keywords\": \"Cartoon, Wolves, Hide-and-Seek, Cardboard City, Alien\",\n",
      "        \"video_summary\": \"The video showcases a series of animated scenes featuring a panda and three cartoon wolves engaging in various activities, from watching TV to building a miniature cardboard town. The wolves, along with a pink dog and a green alien, encounter unexpected situations such as a giant fox descending upon them and a chase involving toy cars and a convertible. The narrative culminates in a heartwarming reunion under a bridge, where the characters express gratitude for their day's adventures. Throughout the video, the characters display a range of emotions and interactions, highlighting themes of friendship and teamwork.\",\n",
      "        \"embedding_scope\": \"clip\",\n",
      "        \"start_offset_sec\": [\n",
      "            0.0,\n",
      "            6.0,\n",
      "            12.0\n",
      "        ],\n",
      "        \"end_offset_sec\": [\n",
      "            6.0,\n",
      "            12.0,\n",
      "            18.0\n",
      "        ],\n",
      "        \"embedding\": {\n",
      "            \"0\": [\n",
      "                0.04080625,\n",
      "                0.0086980555,\n",
      "                0.00096186635\n",
      "            ],\n",
      "            \"1\": [\n",
      "                0.05161131,\n",
      "                -0.0063618324,\n",
      "                -0.008135624\n",
      "            ],\n",
      "            \"2\": [\n",
      "                0.050463274,\n",
      "                0.0006376326,\n",
      "                -0.010785032\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The positional index of the document\n",
    "i = 0\n",
    "\n",
    "# Iterate through the first 3 embeddings in vespa_feed\n",
    "for i in range(\n",
    "    min(3, len(vespa_feed))\n",
    "):  # Ensure we don't exceed the length of vespa_feed\n",
    "    # Limit the embedding to the first 3 keys and first 5 values for each key\n",
    "    embedding = vespa_feed[i][\"fields\"][\"embeddings\"]\n",
    "    embedding_sample = {key: values[:3] for key, values in list(embedding.items())[:3]}\n",
    "\n",
    "# Beautify and print the first document with only the first 5 embedding values\n",
    "pretty_json = json.dumps(\n",
    "    {\n",
    "        \"id\": vespa_feed[i][\"id\"],\n",
    "        \"fields\": {\n",
    "            \"video_url\": vespa_feed[i][\"fields\"][\"video_url\"],\n",
    "            \"title\": vespa_feed[i][\"fields\"][\"title\"],\n",
    "            \"keywords\": vespa_feed[i][\"fields\"][\"keywords\"],\n",
    "            \"video_summary\": vespa_feed[i][\"fields\"][\"video_summary\"],\n",
    "            \"embedding_scope\": vespa_feed[i][\"fields\"][\"embedding_scope\"],\n",
    "            \"start_offset_sec\": vespa_feed[i][\"fields\"][\"start_offset_sec\"][:3],\n",
    "            \"end_offset_sec\": vespa_feed[i][\"fields\"][\"end_offset_sec\"][:3],\n",
    "            \"embedding\": embedding_sample,\n",
    "        },\n",
    "    },\n",
    "    indent=4,\n",
    ")\n",
    "\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JPgWYO_zDfBY",
   "metadata": {
    "id": "JPgWYO_zDfBY"
   },
   "source": [
    "Now we can feed to Vespa using `feed_iterable` which accepts any `Iterable` and an optional callback function where we can\n",
    "check the outcome of each operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3d650aa",
   "metadata": {
    "id": "d3d650aa"
   },
   "outputs": [],
   "source": [
    "def callback(response: VespaResponse, id: str):\n",
    "    if not response.is_successful():\n",
    "        print(\n",
    "            f\"Failed to feed document {id} with status code {response.status_code}: Reason {response.get_json()}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Feed data into Vespa synchronously\n",
    "app.feed_iterable(vespa_feed, schema=\"videos\", callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1TmrMnhEQx2",
   "metadata": {
    "id": "e1TmrMnhEQx2"
   },
   "source": [
    "# 4. Performing search on the videos\n",
    "\n",
    "\n",
    "## 4.1 Performing a hybrid search on the video\n",
    "\n",
    "As an example query, we will retrieve all the chunks which shows Santa Claus on his sleigh. The first step is to generate a text embedding for `Santa Claus on his sleigh` using the `Marengo-retrieval-2.7` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8wxSLkGkpL8w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wxSLkGkpL8w",
    "outputId": "0ebfcab2-9e6d-4193-efbc-e3c3994492c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a text embedding\n",
      " Model: Marengo-retrieval-2.7\n",
      " Embedding Dimension: 1024\n",
      " Sample 5 values from array: [-0.018066406, -0.0065307617, 0.05859375, -0.033447266, -0.02368164]\n"
     ]
    }
   ],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "user_query = \"Santa Claus on his sleigh\"\n",
    "\n",
    "res = client.embed.create(\n",
    "    model_name=\"Marengo-retrieval-2.7\",\n",
    "    text=user_query,\n",
    ")\n",
    "\n",
    "print(\"Created a text embedding\")\n",
    "print(f\" Model: {res.model_name}\")\n",
    "if res.text_embedding is not None and res.text_embedding.segments is not None:\n",
    "    q_embedding = res.text_embedding.segments[0].embeddings_float\n",
    "    print(f\" Embedding Dimension: {len(q_embedding)}\")\n",
    "    print(f\" Sample 5 values from array: {q_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oOR1PuSRSlh4",
   "metadata": {
    "id": "oOR1PuSRSlh4"
   },
   "source": [
    "The following uses dense vector representations of the query embedding obtained previously and document and matching is performed and accelerated by Vespa's support for\n",
    "[approximate nearest neighbor search](https://docs.vespa.ai/en/approximate-nn-hnsw.html).\n",
    "\n",
    "The output is limited to the top 1 hit, as we only have a sample of 3 videos. The top hit returned was based on a hybrid ranking based on a bm25 ranking based on a lexical search on the text, keywords and summary of the video, performed as a first phase, and similarity search on the embeddings.\n",
    "\n",
    "We can see as part of the `match-features`, the segment 212 in the video was the one providing the highest match.\n",
    "\n",
    "We also calculate the similarities as part of the `summary-features` for the rest of the segments so we can look for top N segments within a video, optionally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N4XEyB4pYC7l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4XEyB4pYC7l",
    "outputId": "836526cc-80b3-4758-c96c-4d40bc859298"
   },
   "outputs": [],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "    response: VespaQueryResponse = session.query(\n",
    "        yql=\"select * from videos where userQuery() OR ({targetHits:100}nearestNeighbor(embeddings,q))\",\n",
    "        query=user_query,\n",
    "        ranking=\"hybrid\",\n",
    "        hits=1,\n",
    "        body={\"input.query(q)\": q_embedding},\n",
    "    )\n",
    "    assert response.is_successful()\n",
    "\n",
    "for hit in response.hits:\n",
    "    print(json.dumps(hit, indent=4))\n",
    "\n",
    "# response.get_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09ea78",
   "metadata": {},
   "source": [
    "You should see output similar to this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"id:videos:videos::13bcb994b389c9d925993e611877e40b\",\n",
    "    \"relevance\": 0.47162757625475055,\n",
    "    \"source\": \"videosearch_content\",\n",
    "    \"fields\": {\n",
    "        \"matchfeatures\": {\n",
    "            \"closest(embeddings)\": {\n",
    "                \"type\": \"tensor<float>(p{})\",\n",
    "                \"cells\": {\n",
    "                    \"212\": 1.0\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"sddocname\": \"videos\",\n",
    "        \"documentid\": \"id:videos:videos::13bcb994b389c9d925993e611877e40b\",\n",
    "        \"video_url\": \"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\",\n",
    "        \"title\": \"Twas the night before Christmas\",\n",
    "        \"keywords\": \"Christmas Eve, Santa Claus, Clockmaker, Snowy Night, Mouse Characters\",\n",
    "        \"video_summary\": \"The video is an animated adaptation of \\\"A Visit from St. Nicholas,\\\" commonly known as \\\"The Night Before Christmas,\\\" narrated and sung by Joel Grey. It features a town where the residents, including a clockmaker named Joshua Trundle and his family, are troubled by Santa's absence due to a critical letter published in the local newspaper. The story unfolds with the clockmaker's son, Albert, realizing his mistake and attempting to fix a malfunctioning clock in the town hall that was meant to welcome Santa. Despite initial setbacks, the community's efforts eventually lead to Santa's arrival, restoring joy and belief in the magic of Christmas. The video concludes with Santa Claus descending through chimneys to deliver gifts, symbolizing the triumph of hope and the spirit of the holiday.\",\n",
    "        \"embedding_scope\": \"clip\",\n",
    "        \"start_offset_sec\": [\n",
    "            0.0,\n",
    "            6.0,\n",
    "            12.0,\n",
    "            18.0,\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bnbWlc62nhyb",
   "metadata": {
    "id": "bnbWlc62nhyb"
   },
   "source": [
    "In order to process the results above in a more consumable format and sort out the top N segments based on similarities, we can do this more conveniently in a pandas dataframe below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vGDIF53MvkdR",
   "metadata": {
    "id": "vGDIF53MvkdR"
   },
   "outputs": [],
   "source": [
    "def get_top_n_similarity_matches(data, N=5):\n",
    "    \"\"\"\n",
    "    Function to extract the top N similarity scores and their corresponding start and end offsets.\n",
    "\n",
    "    Args:\n",
    "    - data (dict): Input JSON-like structure containing similarities and offsets.\n",
    "    - N (int): The number of top similarity scores to return.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the top N similarity scores and their corresponding offsets.\n",
    "    \"\"\"\n",
    "    # Extract relevant fields\n",
    "    similarities = data[\"fields\"][\"summaryfeatures\"][\"similarities\"][\"cells\"]\n",
    "    start_offset_sec = data[\"fields\"][\"start_offset_sec\"]\n",
    "    end_offset_sec = data[\"fields\"][\"end_offset_sec\"]\n",
    "\n",
    "    # Convert similarity scores to a list of tuples (index, similarity_score) and sort by similarity score\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract top N similarity scores\n",
    "    top_n_similarities = sorted_similarities[:N]\n",
    "\n",
    "    # Prepare results\n",
    "    results = []\n",
    "    for index_str, score in top_n_similarities:\n",
    "        index = int(index_str)\n",
    "        if index < len(start_offset_sec):\n",
    "            result = {\n",
    "                \"index\": index,\n",
    "                \"similarity_score\": score,\n",
    "                \"start_offset_sec\": start_offset_sec[index],\n",
    "                \"end_offset_sec\": end_offset_sec[index],\n",
    "            }\n",
    "        else:\n",
    "            result = {\n",
    "                \"index\": index,\n",
    "                \"similarity_score\": score,\n",
    "                \"start_offset_sec\": None,\n",
    "                \"end_offset_sec\": None,\n",
    "            }\n",
    "        results.append(result)\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ySanRKGLpAjB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ySanRKGLpAjB",
    "outputId": "ae8f0c5c-fd03-41a5-fc6e-880685c13818"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_result\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 203,\n        \"max\": 231,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          203,\n          230,\n          231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011396681973411668,\n        \"min\": 0.391671359539032,\n        \"max\": 0.43537065386772156,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.40329158306121826,\n          0.41800743341445923,\n          0.40599969029426575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_offset_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.874877690685246,\n        \"min\": 1218.0,\n        \"max\": 1386.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1218.0,\n          1380.0,\n          1386.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_offset_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.874877690685246,\n        \"min\": 1224.0,\n        \"max\": 1392.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1224.0,\n          1386.0,\n          1392.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_result"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-372bd61b-6feb-45c5-b2dc-cf99cf5407d7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>start_offset_sec</th>\n",
       "      <th>end_offset_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>0.435371</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230</td>\n",
       "      <td>0.418007</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>1386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>0.411242</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>0.409344</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>1272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>1254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>231</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>1392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209</td>\n",
       "      <td>0.404767</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>1260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>229</td>\n",
       "      <td>0.403729</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>1380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>203</td>\n",
       "      <td>0.403292</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>1224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>207</td>\n",
       "      <td>0.391671</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-372bd61b-6feb-45c5-b2dc-cf99cf5407d7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-372bd61b-6feb-45c5-b2dc-cf99cf5407d7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-372bd61b-6feb-45c5-b2dc-cf99cf5407d7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-559ae005-2e79-4585-bbc2-fa66b3bc872a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-559ae005-2e79-4585-bbc2-fa66b3bc872a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-559ae005-2e79-4585-bbc2-fa66b3bc872a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_725cbf76-9d82-4b6c-8155-ccbd6074e4e9\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_result')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_725cbf76-9d82-4b6c-8155-ccbd6074e4e9 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_result');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   index  similarity_score  start_offset_sec  end_offset_sec\n",
       "0    212          0.435371            1272.0          1278.0\n",
       "1    230          0.418007            1380.0          1386.0\n",
       "2    210          0.411242            1260.0          1266.0\n",
       "3    211          0.409344            1266.0          1272.0\n",
       "4    208          0.408644            1248.0          1254.0\n",
       "5    231          0.406000            1386.0          1392.0\n",
       "6    209          0.404767            1254.0          1260.0\n",
       "7    229          0.403729            1374.0          1380.0\n",
       "8    203          0.403292            1218.0          1224.0\n",
       "9    207          0.391671            1242.0          1248.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = get_top_n_similarity_matches(response.hits[0], N=10)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sYoc3zy3pNqV",
   "metadata": {
    "id": "sYoc3zy3pNqV"
   },
   "source": [
    "## 5. Review results (Optional)\n",
    "\n",
    "We can review the results by spinning up a video player in the notebook and check the segments identified and judge by ourselves.\n",
    "\n",
    "But, first we need to obtain the contiguous segments, add 3 seconds overlap in the consolidated segments and convert to MM:SS so we can quickly find the segments to watch in the player. Let's write a function that takes the response as an input and provides the consolidated segments to view in the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "244lqkpvymGH",
   "metadata": {
    "id": "244lqkpvymGH"
   },
   "outputs": [],
   "source": [
    "def concatenate_contiguous_segments(df):\n",
    "    \"\"\"\n",
    "    Function to concatenate contiguous segments based on their start and end offsets.\n",
    "    Converts the concatenated segments to MM:SS format.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame with columns 'start_offset_sec' and 'end_offset_sec'.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples with concatenated segments in MM:SS format as (start_time, end_time).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return []\n",
    "\n",
    "    # Sort by start_offset_sec for ordered processing\n",
    "    df = df.sort_values(by=\"start_offset_sec\").reset_index(drop=True)\n",
    "\n",
    "    # Initialize the list to hold concatenated segments\n",
    "    concatenated_segments = []\n",
    "\n",
    "    # Initialize the first segment\n",
    "    start = df.iloc[0][\"start_offset_sec\"]\n",
    "    end = df.iloc[0][\"end_offset_sec\"]\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        current_start = df.iloc[i][\"start_offset_sec\"]\n",
    "        current_end = df.iloc[i][\"end_offset_sec\"]\n",
    "\n",
    "        # Check if the current segment is contiguous with the previous one\n",
    "        if current_start <= end:\n",
    "            # Extend the segment if it is contiguous\n",
    "            end = max(end, current_end)\n",
    "        else:\n",
    "            # Add the previous segment to the result list in MM:SS format\n",
    "            concatenated_segments.append(\n",
    "                (convert_seconds_to_mmss(start - 3), convert_seconds_to_mmss(end + 3))\n",
    "            )\n",
    "            # Start a new segment\n",
    "            start = current_start\n",
    "            end = current_end\n",
    "\n",
    "    # Add the final segment\n",
    "    concatenated_segments.append(\n",
    "        (convert_seconds_to_mmss(start - 3), convert_seconds_to_mmss(end + 3))\n",
    "    )\n",
    "\n",
    "    return concatenated_segments\n",
    "\n",
    "\n",
    "def convert_seconds_to_mmss(seconds):\n",
    "    \"\"\"\n",
    "    Converts seconds to MM:SS format.\n",
    "\n",
    "    Args:\n",
    "    - seconds (float): Time in seconds.\n",
    "\n",
    "    Returns:\n",
    "    - str: Time in MM:SS format.\n",
    "    \"\"\"\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes:02}:{seconds:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "azg1FfNCzEpV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azg1FfNCzEpV",
    "outputId": "610f5977-9a9c-4cca-bb12-eb639acea71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20:15', '20:27'), ('20:39', '21:21'), ('22:51', '23:15')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = concatenate_contiguous_segments(df_result)\n",
    "segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XKK-tQMGp57L",
   "metadata": {
    "id": "XKK-tQMGp57L"
   },
   "source": [
    "We can now spin-up the player and review the segments of interest.\n",
    "Video player is set to start in the middle of the first segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brwDc367FHzX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "brwDc367FHzX",
    "outputId": "a6b5a8d5-c696-4a38-f09c-9bcd31eb22a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video id=\"myVideo\" width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>\n",
       "\n",
       "<script>\n",
       "  var video = document.getElementById(\"myVideo\");\n",
       "  video.addEventListener('loadedmetadata', function() {\n",
       "    video.currentTime = 1221;\n",
       "  }, false);\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\"\n",
    "\n",
    "video_player = f\"\"\"\n",
    "<video id=\"myVideo\" width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HTML(video_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf10c4db",
   "metadata": {
    "id": "cf10c4db"
   },
   "source": [
    "## 6. Clean-up\n",
    "\n",
    "The following will delete the application and data from the dev environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9d44767",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9d44767",
    "outputId": "866323ba-9e02-43f4-98b2-29feeefea21f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deactivated vespa-presales.videosearch in dev.aws-us-east-1c\n",
      "Deleted instance vespa-presales.videosearch.default\n"
     ]
    }
   ],
   "source": [
    "vespa_cloud.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B4zTc3eApSFy",
   "metadata": {
    "id": "B4zTc3eApSFy"
   },
   "source": [
    "The following will delete the index created earlier where videos where uploaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7BAlC6R8pZD1",
   "metadata": {
    "id": "7BAlC6R8pZD1"
   },
   "outputs": [],
   "source": [
    "# Creating a client\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "client.index.delete(index_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
