{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "b3ae8a2b",
            "metadata": {
                "id": "b3ae8a2b"
            },
            "source": [
                "<picture>\n",
                "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
                "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
                "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
                "</picture>\n",
                "\n",
                "# Standalone ColBERT + Vespa for long-context ranking\n",
                "\n",
                "This is a guide on how to use the [ColBERT](https://github.com/stanford-futuredata/ColBERT) package to produce token-level\n",
                "vectors. This as an alternative for using the native Vespa [colbert embedder](https://docs.vespa.ai/en/embedding.html#colbert-embedder).\n",
                "\n",
                "This guide illustrates how to feed multiple passages per Vespa document (long-context)\n",
                "\n",
                "- Compress token vectors using binarization compatible with Vespa `unpack_bits`\n",
                "- Use Vespa hex feed format for binary vectors with mixed vespa tensors\n",
                "- How to query Vespa with the ColBERT query tensor representation\n",
                "\n",
                "Read more about [Vespa Long-Context ColBERT](https://blog.vespa.ai/announcing-long-context-colbert-in-vespa/).\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/colbert_standalone_long_context_Vespa-cloud.ipynb)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4ffa3cbe",
            "metadata": {
                "id": "4ffa3cbe"
            },
            "outputs": [],
            "source": [
                "!pip3 install -U pyvespa colbert-ai numpy torch vespacli transformers<=4.49.0"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17d765d7",
            "metadata": {},
            "source": [
                "Load a checkpoint with ColBERT and obtain document and query embeddings\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9ad221c5",
            "metadata": {},
            "outputs": [],
            "source": [
                "from colbert.modeling.checkpoint import Checkpoint\n",
                "from colbert.infra import ColBERTConfig\n",
                "\n",
                "ckpt = Checkpoint(\n",
                "    \"colbert-ir/colbertv2.0\", colbert_config=ColBERTConfig(root=\"experiments\")\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "93efc596",
            "metadata": {},
            "source": [
                "A few sample documents:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "id": "bcadc48f",
            "metadata": {},
            "outputs": [],
            "source": [
                "document_passages = [\n",
                "    \"Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.\",\n",
                "    \"Born in Maida Vale, London, Turing was raised in southern England. He graduated from King's College, Cambridge, with a degree in mathematics.\",\n",
                "    \"After the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer.\",\n",
                "    \"Turing has an extensive legacy with statues of him and many things named after him, including an annual award for computer science innovations.\",\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b8154eb",
            "metadata": {},
            "outputs": [],
            "source": [
                "document_token_vectors = ckpt.docFromText(document_passages)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "23b2e1f4",
            "metadata": {},
            "source": [
                "See the shape of the ColBERT document embeddings:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "id": "376f809c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([4, 35, 128])"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "document_token_vectors.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "id": "f82fa1d3",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([32, 128])"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "query_vectors = ckpt.queryFromText([\"Who was Alan Turing?\"])[0]\n",
                "query_vectors.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "95f7f71b",
            "metadata": {},
            "source": [
                "The query is always padded to 32 so in the above we have 32 query token vectors.\n",
                "\n",
                "Routines for binarization and output in Vespa tensor format that can be used in queries and JSON feed.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "id": "5e43f0fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "from binascii import hexlify\n",
                "from typing import List, Dict\n",
                "\n",
                "\n",
                "def binarize_token_vectors_hex(vectors: torch.Tensor) -> Dict[str, str]:\n",
                "    # Notice axix=2 to pack the bits in the last dimension, which is the token level vectors\n",
                "    binarized_token_vectors = np.packbits(np.where(vectors > 0, 1, 0), axis=2).astype(\n",
                "        np.int8\n",
                "    )\n",
                "    vespa_tensor = list()\n",
                "    for chunk_index in range(0, len(binarized_token_vectors)):\n",
                "        token_vectors = binarized_token_vectors[chunk_index]\n",
                "        for token_index in range(0, len(token_vectors)):\n",
                "            values = str(hexlify(token_vectors[token_index].tobytes()), \"utf-8\")\n",
                "            if (\n",
                "                values == \"00000000000000000000000000000000\"\n",
                "            ):  # skip empty vectors due to padding with batch of passages\n",
                "                continue\n",
                "            vespa_tensor_cell = {\n",
                "                \"address\": {\"context\": chunk_index, \"token\": token_index},\n",
                "                \"values\": values,\n",
                "            }\n",
                "            vespa_tensor.append(vespa_tensor_cell)\n",
                "\n",
                "    return vespa_tensor\n",
                "\n",
                "\n",
                "def float_query_token_vectors(vectors: torch.Tensor) -> Dict[str, List[float]]:\n",
                "    vespa_token_feed = dict()\n",
                "    for index in range(0, len(vectors)):\n",
                "        vespa_token_feed[index] = vectors[index].tolist()\n",
                "    return vespa_token_feed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6857e5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "print(json.dumps(binarize_token_vectors_hex(document_token_vectors)))\n",
                "print(json.dumps(float_query_token_vectors(query_vectors)))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "da356d25",
            "metadata": {
                "id": "da356d25"
            },
            "source": [
                "## Defining the Vespa application\n",
                "\n",
                "[PyVespa](https://vespa-engine.github.io/pyvespa/) helps us build the [Vespa application package](https://docs.vespa.ai/en/application-packages.html).\n",
                "A Vespa application package consists of configuration files, schemas, models, and code (plugins).\n",
                "\n",
                "First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html) with the fields we want to store and their type.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "id": "0dca2378",
            "metadata": {
                "id": "0dca2378"
            },
            "outputs": [],
            "source": [
                "from vespa.package import Schema, Document, Field\n",
                "\n",
                "colbert_schema = Schema(\n",
                "    name=\"doc\",\n",
                "    document=Document(\n",
                "        fields=[\n",
                "            Field(name=\"id\", type=\"string\", indexing=[\"summary\"]),\n",
                "            Field(\n",
                "                name=\"passages\",\n",
                "                type=\"array<string>\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                index=\"enable-bm25\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"colbert\",\n",
                "                type=\"tensor<int8>(context{}, token{}, v[16])\",\n",
                "                indexing=[\"attribute\", \"summary\"],\n",
                "            ),\n",
                "        ]\n",
                "    ),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "id": "66c5da1d",
            "metadata": {
                "id": "66c5da1d"
            },
            "outputs": [],
            "source": [
                "from vespa.package import ApplicationPackage\n",
                "\n",
                "vespa_app_name = \"colbertlong\"\n",
                "vespa_application_package = ApplicationPackage(\n",
                "    name=vespa_app_name, schema=[colbert_schema]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5ea4ff0d",
            "metadata": {},
            "source": [
                "Note that we use max sim in the first phase ranking over all \n",
                "the hits that are retrieved by the query logic. Also note that asymmetric MaxSim where we \n",
                "use `unpack_bits` to obtain a 128-d float vector representation from the binary vector representation. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "id": "a8ce5624",
            "metadata": {
                "id": "a8ce5624"
            },
            "outputs": [],
            "source": [
                "from vespa.package import RankProfile, Function, FirstPhaseRanking\n",
                "\n",
                "colbert_profile = RankProfile(\n",
                "    name=\"default\",\n",
                "    inputs=[(\"query(qt)\", \"tensor<float>(querytoken{}, v[128])\")],\n",
                "    functions=[\n",
                "        Function(\n",
                "            name=\"max_sim_per_context\",\n",
                "            expression=\"\"\"\n",
                "                sum(\n",
                "                    reduce(\n",
                "                        sum(\n",
                "                            query(qt) * unpack_bits(attribute(colbert)) , v\n",
                "                        ),\n",
                "                        max, token\n",
                "                    ),\n",
                "                    querytoken\n",
                "                )\n",
                "            \"\"\",\n",
                "        ),\n",
                "        Function(\n",
                "            name=\"max_sim\", expression=\"reduce(max_sim_per_context, max, context)\"\n",
                "        ),\n",
                "    ],\n",
                "    first_phase=FirstPhaseRanking(expression=\"max_sim\"),\n",
                "    match_features=[\"max_sim_per_context\"],\n",
                ")\n",
                "colbert_schema.add_rank_profile(colbert_profile)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "846545f9",
            "metadata": {
                "id": "846545f9"
            },
            "source": [
                "## Deploy the application to Vespa Cloud\n",
                "\n",
                "With the configured application, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/).\n",
                "\n",
                "To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n",
                "\n",
                "Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one).\n",
                "This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial).\n",
                "\n",
                "Make note of the tenant name, it is used in the next steps.\n",
                "\n",
                "> Note: Deployments to dev and perf expire after 7 days of inactivity, i.e., 7 days after running deploy. This applies to all plans, not only the Free Trial. Use the Vespa Console to extend the expiry period, or redeploy the application to add 7 more days.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "id": "b5fddf9f",
            "metadata": {
                "id": "b5fddf9f"
            },
            "outputs": [],
            "source": [
                "from vespa.deployment import VespaCloud\n",
                "import os\n",
                "\n",
                "# Replace with your tenant name from the Vespa Cloud Console\n",
                "tenant_name = \"vespa-team\"\n",
                "\n",
                "# Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "key = os.getenv(\"VESPA_TEAM_API_KEY\", None)\n",
                "if key is not None:\n",
                "    key = key.replace(r\"\\n\", \"\\n\")  # To parse key correctly\n",
                "\n",
                "vespa_cloud = VespaCloud(\n",
                "    tenant=tenant_name,\n",
                "    application=vespa_app_name,\n",
                "    key_content=key,  # Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "    application_package=vespa_application_package,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa9baa5a",
            "metadata": {
                "id": "fa9baa5a"
            },
            "source": [
                "Now deploy the app to Vespa Cloud dev zone.\n",
                "\n",
                "The first deployment typically takes 2 minutes until the endpoint is up.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fe954dc4",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "fe954dc4",
                "outputId": "a0764bd3-98c2-492a-b8d9-b99ecacf4bdb"
            },
            "outputs": [],
            "source": [
                "from vespa.application import Vespa\n",
                "\n",
                "app: Vespa = vespa_cloud.deploy()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "acad963e",
            "metadata": {},
            "source": [
                "Use Vespa tensor `blocks` format for mixed tensors (two mapped dimensions with one dense) [doc](https://docs.vespa.ai/en/reference/document-json-format.html#tensor).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "id": "50356013",
            "metadata": {},
            "outputs": [],
            "source": [
                "from vespa.io import VespaResponse\n",
                "\n",
                "vespa_feed_format = {\n",
                "    \"id\": \"1\",\n",
                "    \"passages\": document_passages,\n",
                "    \"colbert\": {\"blocks\": binarize_token_vectors_hex(document_token_vectors)},\n",
                "}\n",
                "# synchrounous feed (this is blocking and slow, but few docs..)\n",
                "with app.syncio() as sync:\n",
                "    response: VespaResponse = sync.feed_data_point(\n",
                "        data_id=1, fields=vespa_feed_format, schema=\"doc\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cebada8d",
            "metadata": {},
            "source": [
                "### Querying Vespa with ColBERT tensors \n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2f97a38c",
            "metadata": {},
            "source": [
                "This example uses brute-force \"true\" search without a retrieval step using nearestNeighbor or keywords.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1a2c7f53",
            "metadata": {},
            "outputs": [],
            "source": [
                "from vespa.io import VespaQueryResponse\n",
                "import json\n",
                "\n",
                "response: VespaQueryResponse = app.query(\n",
                "    yql=\"select * from doc where true\",\n",
                "    ranking=\"default\",\n",
                "    body={\n",
                "        \"presentation.format.tensors\": \"short-value\",\n",
                "        \"input.query(qt)\": float_query_token_vectors(query_vectors),\n",
                "    },\n",
                ")\n",
                "assert response.is_successful()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0bb213b3",
            "metadata": {},
            "source": [
                "You should see output similar to this:\n",
                "\n",
                "```json\n",
                "{\n",
                "  \"id\": \"id:doc:doc::1\",\n",
                "  \"relevance\": 100.0651626586914,\n",
                "  \"source\": \"colbertlong_content\",\n",
                "  \"fields\": {\n",
                "    \"matchfeatures\": {\n",
                "      \"max_sim_per_context\": {\n",
                "        \"0\": 100.0651626586914,\n",
                "        \"1\": 62.7861328125,\n",
                "        \"2\": 67.44772338867188,\n",
                "        \"3\": 60.133323669433594\n",
                "      }\n",
                "    },\n",
                "    \"sddocname\": \"doc\",\n",
                "    \"documentid\": \"id:doc:doc::1\",\n",
                "    \"id\": \"1\",\n",
                "    \"passages\": [\n",
                "      \"Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.\",\n",
                "      \"Born in Maida Vale, London, Turing was raised in southern England. He graduated from King's College, Cambridge, with a degree in mathematics.\",\n",
                "      \"After the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer.\",\n",
                "      \"Turing has an extensive legacy with statues of him and many things named after him, including an annual award for computer science innovations.\"\n",
                "    ],\n",
                "    \"colbert\": [\n",
                "      {\n",
                "        \"address\": {\n",
                "          \"context\": \"0\",\n",
                "          \"token\": \"0\"\n",
                "        },\n",
                "        \"values\": [\n",
                "          1,\n",
                "          120,\n",
                "          69,\n",
                "          0,\n",
                "          33,\n",
                "          -60,\n",
                "          -58,\n",
                "          -95,\n",
                "          -120,\n",
                "          32,\n",
                "          -127,\n",
                "          67,\n",
                "          -51,\n",
                "          68,\n",
                "          -106,\n",
                "          -12\n",
                "        ]\n",
                "      },\n",
                "      {\n",
                "        \"address\": {\n",
                "          \"context\": \"0\",\n",
                "          \"token\": \"1\"\n",
                "        },\n",
                "        \"values\": [\n",
                "          -122,\n",
                "          60,\n",
                "          9,\n",
                "          -128,\n",
                "          97,\n",
                "          -60,\n",
                "          -58,\n",
                "          -95,\n",
                "          -80,\n",
                "          112,\n",
                "          -127,\n",
                "          67,\n",
                "          -99,\n",
                "          68,\n",
                "          -106,\n",
                "          -28\n",
                "        ]\n",
                "      },\n",
                "      \"...\"\n",
                "    ],\n",
                "\n",
                "  }\n",
                "}\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5ed54d12",
            "metadata": {},
            "source": [
                "As can be seen from the matchfeatures, the first context (index 0) scored the highest and this is the score that is used to score the entire document.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "71e310e3",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "71e310e3",
                "outputId": "991b1965-6c33-4985-e873-a92c43695528"
            },
            "outputs": [],
            "source": [
                "vespa_cloud.delete()"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.11.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        },
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
